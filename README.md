#### В ноутбуке совсем нет пометок, поэтому они будут здесь
#### Архитектурой выступил Fasttext для получения векторного представления слов, за ним идет LSTM и на вершине линейные слои с дропаутом и релу между ними.
### Тренировочная выборка была разделена на train/test с пропорциями 90/10
### Модель обучается и определяет класс слова. Их 3:
1. Слово в нижнем регистре;
2. Слово начинается с заглавной, все остальные в нижнем регистре;
3. Слово в верхнем регистре;
4. Последний класс для паддинга.
### Наверно добавление класса - не совсем интуитивно понятное решение, но оно было сделано потому что мне хотелось, чтоб модель не примешивала падинг слово к какому-то другому классу. А паддинг нужен для создания батча - ускорения обучения на довольно большой выборке.
### На тестовой выборке я пожертвовал своим временем и прогнал сеть на каждом названии и не формировал батчи.